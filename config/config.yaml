models:
  default: "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free"
  parameters:
    max_tokens: 256
    temperature: 0.7
    top_p: 0.7
    top_k: 50
    repetition_penalty: 1

search:
  max_results: 10
  timeout: 30

cache:
  enabled: true
  expiry: 3600  # 1 hour